import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
from datetime import datetime
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Page configuration
st.set_page_config(
    page_title="Pr√©diction Valeur Fonci√®re",
    page_icon="üè†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        margin-bottom: 2rem;
    }
    .metric-container {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .prediction-result {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 1rem;
        text-align: center;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #e8f4fd;
        border-left: 4px solid #2E86AB;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 0.25rem;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="main-header">üè† Pr√©diction de Valeur Fonci√®re d une Maison</h1>', unsafe_allow_html=True)
st.markdown("---")

# Enhanced function to load geographical data
@st.cache_data
def load_geo_data():
    """Load geographical data from CSV file with enhanced error handling"""
    file_path = 'Liste_Departement_Ville_ValeursFoncieres-all_fitre.csv'
    
    try:
        # First, try to detect the file structure
        sample = pd.read_csv(file_path, nrows=5)
        
        # Check if first row contains headers
        has_headers = not all(sample.iloc[0].apply(lambda x: str(x).isdigit()))
        
        # Load the complete file
        if has_headers:
            geo_df = pd.read_csv(file_path, header=0)
            if len(geo_df.columns) >= 3:
                geo_df.columns = ['Code_departement', 'Code_postal', 'Commune']
        else:
            geo_df = pd.read_csv(file_path, 
                               names=['Code_departement', 'Code_postal', 'Commune'],
                               header=None)
        
        # Data cleaning and type conversion
        geo_df['Code_departement'] = pd.to_numeric(geo_df['Code_departement'], errors='coerce')
        geo_df['Code_postal'] = pd.to_numeric(geo_df['Code_postal'], errors='coerce')
        
        # Remove rows with missing values
        initial_count = len(geo_df)
        geo_df = geo_df.dropna(subset=['Code_departement', 'Code_postal'])
        cleaned_count = len(geo_df)
        
        # Convert to appropriate types
        geo_df['Code_departement'] = geo_df['Code_departement'].astype('int32')
        geo_df['Code_postal'] = geo_df['Code_postal'].astype('int32')
        geo_df['Commune'] = geo_df['Commune'].str.strip()
        
        # Sort for better user experience
        geo_df = geo_df.sort_values(['Code_departement', 'Code_postal', 'Commune'])
        
        logger.info(f"Geographical data loaded: {cleaned_count}/{initial_count} rows")
#        st.success(f"‚úÖ Donn√©es g√©ographiques charg√©es: {cleaned_count:,} lignes")
        
        if cleaned_count < initial_count:
            st.info(f"‚ÑπÔ∏è {initial_count - cleaned_count} lignes avec des donn√©es manquantes ont √©t√© supprim√©es")
        
        return geo_df
        
    except FileNotFoundError:
        st.error(f"‚ùå Fichier '{file_path}' introuvable")
        st.info("Assurez-vous que le fichier CSV est dans le r√©pertoire de l'application")
        return pd.DataFrame(columns=['Code_departement', 'Code_postal', 'Commune'])
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement: {str(e)}")
        with st.expander("üîß Format de fichier attendu"):
            st.code("Code_departement,Code_postal,Commune\n78,78980,SAINT-ILLIERS-LE-BOIS")
        return pd.DataFrame(columns=['Code_departement', 'Code_postal', 'Commune'])

# Enhanced function to load model and encoders
@st.cache_resource
def load_model_and_encoders(model_choice):
    """Load model and encoders with enhanced error handling"""
    
    # CORRECTION: Essayer les deux noms de fichiers possibles pour CatBoost
    if model_choice == "cb":
        # Essayer d'abord model_cb_b.pkl, puis model_cb.pkl
        possible_paths = ['model_cb_b.pkl', 'model_cb.pkl']
        model_path = None
        
        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                st.info(f"üìÅ Fichier CatBoost trouv√©: {path}")
                break
        
        if model_path is None:
            st.error(f"‚ùå Aucun fichier CatBoost trouv√©. Fichiers recherch√©s: {possible_paths}")
            return None, None, {}
            
    elif model_choice == "lgb":
        model_path = 'model_lgb.pkl'
    else:
        model_path = f'model_{model_choice}.pkl'
    
    encoders_path = 'encoders.pkl'
    
    model = None
    encoders = None
    model_info = {}
    
    # Load model with multiple protocols and diagnostics
    try:
        if os.path.exists(model_path):
            # First, let's diagnose the file
            file_size = os.path.getsize(model_path)
            st.info(f"üìÅ Fichier utilis√©: {model_path} ({file_size} bytes)")
            
            # Check if file is empty or too small
            if file_size < 10:
                st.error("‚ùå Le fichier est trop petit ou vide")
                return None, None, {}
            
            # Read first few bytes to check file signature
            try:
                with open(model_path, 'rb') as f:
                    first_bytes = f.read(20)
                    st.info(f"üîç Premiers bytes du fichier: {first_bytes[:10]}")
                    
                    # Check for Git LFS pointer file
                    if first_bytes.startswith(b'version ht'):
                        st.error("üö® FICHIER GIT LFS D√âTECT√â!")
                        st.error("Le fichier est un pointeur Git LFS, pas le mod√®le r√©el.")
                        
                        # Show file content to confirm
                        with open(model_path, 'r', encoding='utf-8') as f:
                            lfs_content = f.read()
                            st.code(lfs_content, language='text')
                        
                        st.info("üí° **Solutions pour r√©cup√©rer le vrai fichier mod√®le:**")
                        st.write("**Option 1 - Git LFS:**")
                        st.code("git lfs pull", language='bash')
                        st.write("**Option 2 - T√©l√©chargement manuel:**")
                        st.write("1. Allez sur votre repository Git")
                        st.write("2. Cliquez sur le fichier .pkl")
                        st.write("3. Cliquez sur 'Download' pour obtenir le vrai fichier")
                        st.write("**Option 3 - Re-g√©n√©ration:**")
                        st.write("Re-entra√Ænez le mod√®le et sauvegardez-le directement")
                        
                        return None, None, {}
                    
                    # Check if it looks like a pickle file
                    elif not (first_bytes.startswith(b'\x80') or first_bytes.startswith(b'(') or first_bytes.startswith(b']')):
                        st.warning("‚ö†Ô∏è Le fichier ne semble pas √™tre un fichier pickle standard")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Impossible de lire les premiers bytes: {e}")
            
            # Try different pickle protocols and encoding methods
            model_loaded = False
            
            # Method 1: Default pickle load
            try:
                with open(model_path, 'rb') as f:
                    model = pickle.load(f)
                model_loaded = True
                st.success(f"‚úÖ Mod√®le {model_choice.upper()} charg√© avec succ√®s (m√©thode standard)!")
            except Exception as e1:
                st.warning(f"‚ö†Ô∏è M√©thode standard √©chou√©e: {str(e1)}")
                
                # Method 2: Try with different pickle protocol
                try:
                    with open(model_path, 'rb') as f:
                        model = pickle.load(f, encoding='latin1')
                    model_loaded = True
                    st.success(f"‚úÖ Mod√®le {model_choice.upper()} charg√© avec succ√®s (encoding latin1)!")
                except Exception as e2:
                    st.warning(f"‚ö†Ô∏è M√©thode latin1 √©chou√©e: {str(e2)}")
                    
                    # Method 3: Try with bytes encoding
                    try:
                        with open(model_path, 'rb') as f:
                            model = pickle.load(f, encoding='bytes')
                        model_loaded = True
                        st.success(f"‚úÖ Mod√®le {model_choice.upper()} charg√© avec succ√®s (encoding bytes)!")
                    except Exception as e3:
                        st.warning(f"‚ö†Ô∏è M√©thode bytes √©chou√©e: {str(e3)}")
                        
                        # Method 4: Try joblib (common for scikit-learn models)
                        try:
                            import joblib
                            model = joblib.load(model_path)
                            model_loaded = True
                            st.success(f"‚úÖ Mod√®le {model_choice.upper()} charg√© avec succ√®s (joblib)!")
                        except Exception as e4:
                            st.warning(f"‚ö†Ô∏è M√©thode joblib √©chou√©e: {str(e4)}")
                            
                            # Method 5: Try opening as text to see content
                            try:
                                with open(model_path, 'r', encoding='utf-8', errors='ignore') as f:
                                    content_preview = f.read(100)
                                    st.error("üîç Aper√ßu du contenu du fichier (premiers 100 caract√®res):")
                                    st.code(content_preview)
                            except:
                                pass
                            
                            st.error(f"‚ùå Toutes les m√©thodes de chargement ont √©chou√©:")
                            st.error(f"  - Standard: {str(e1)}")
                            st.error(f"  - Latin1: {str(e2)}")
                            st.error(f"  - Bytes: {str(e3)}")
                            st.error(f"  - Joblib: {str(e4)}")
                            
                            # Additional diagnostic info
                            st.info("üí° Suggestions de r√©solution:")
                            st.write("1. Le fichier semble corrompu ou dans un format non reconnu")
                            st.write("2. V√©rifiez que le fichier a √©t√© correctement transf√©r√©")
                            st.write("3. Re-g√©n√©rez le fichier .pkl depuis votre environnement d'entra√Ænement")
                            st.write("4. Le fichier pourrait √™tre dans un format diff√©rent (joblib, dill, etc.)")
                            
                            return None, None, {}
            
            if model_loaded:
                logger.info(f"{model_choice.upper()} model loaded successfully")
                
                # NOUVEAU: Extraire les informations du mod√®le pour diagnostic
                try:
                    if hasattr(model, 'feature_names_in_'):
                        model_info['expected_features'] = list(model.feature_names_in_)
                        st.info(f"üîç Mod√®le attend {len(model.feature_names_in_)} features")
                    if hasattr(model, 'n_features_in_'):
                        model_info['n_features'] = model.n_features_in_
                except:
                    pass
                
        else:
            st.error(f"‚ùå Fichier '{model_path}' introuvable")
            return None, None, {}
    except Exception as e:
        st.error(f"‚ùå Erreur inattendue lors du chargement du mod√®le: {str(e)}")
        return None, None, {}
    
    # Load encoders with similar error handling
    try:
        if os.path.exists(encoders_path):
            try:
                with open(encoders_path, 'rb') as f:
                    encoders = pickle.load(f)
                st.success("‚úÖ Encodeurs charg√©s avec succ√®s!")
            except:
                # Try with encoding fallback for encoders too
                try:
                    with open(encoders_path, 'rb') as f:
                        encoders = pickle.load(f, encoding='latin1')
                    st.success("‚úÖ Encodeurs charg√©s avec succ√®s (encoding latin1)!")
                except:
                    st.warning("‚ö†Ô∏è Erreur lors du chargement des encodeurs - utilisation par d√©faut")
                    encoders = None
            
            logger.info("Encoders loaded successfully")
            
            # NOUVEAU: Afficher les cl√©s d'encodage disponibles
            if isinstance(encoders, dict):
                st.info(f"üîë Encodeurs disponibles: {list(encoders.keys())}")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erreur lors du chargement des encodeurs: {str(e)}")
        st.info("Utilisation de l'encodage par d√©faut")
    
    return model, encoders, model_info


def encode_categorical_features(input_data, encoders=None):
    """Encode categorical features with EXACT Jupyter consistency"""
    input_encoded = input_data.copy()
    original_values = {}
    encoding_log = []  # NOUVEAU: Log des encodages pour diagnostic
    
    try:
        if encoders is not None and isinstance(encoders, dict):
            # CORRECTION: Encodage strict selon les encodeurs sauvegard√©s
            for col in ['Nature_mutation', 'Type_local', 'Commune']:
                if col in input_encoded.columns:
                    original_val = input_encoded[col].iloc[0]
                    original_values[col] = original_val
                    
                    if col in encoders:
                        try:
                            # CRITIQUE: V√©rifier si la valeur existe dans l'encodeur
                            if hasattr(encoders[col], 'classes_'):
                                # LabelEncoder
                                if original_val in encoders[col].classes_:
                                    encoded_val = encoders[col].transform([original_val])[0]
                                    encoding_log.append(f"{col}: '{original_val}' -> {encoded_val}")
                                else:
                                    # Valeur inconnue - utiliser la strat√©gie par d√©faut
                                    encoded_val = -1  # Ou une autre strat√©gie
                                    encoding_log.append(f"{col}: '{original_val}' -> {encoded_val} (inconnu)")
                            else:
                                # Autre type d'encodeur
                                encoded_val = encoders[col].transform([original_val])[0]
                                encoding_log.append(f"{col}: '{original_val}' -> {encoded_val}")
                            
                            input_encoded[col] = encoded_val
                            
                        except Exception as e:
                            # Fallback si l'encodage √©choue
                            if col == 'Nature_mutation':
                                encoded_val = 0  # Vente = 0
                            elif col == 'Type_local':
                                encoded_val = 0  # Maison = 0  
                            elif col == 'Commune':
                                encoded_val = abs(hash(str(original_val))) % 10000
                            
                            input_encoded[col] = encoded_val
                            encoding_log.append(f"{col}: '{original_val}' -> {encoded_val} (fallback)")
                            logger.warning(f"Fallback encoding for {col}: {e}")
                    else:
                        # Encodeur non disponible - utiliser valeurs par d√©faut
                        if col == 'Nature_mutation':
                            encoded_val = 0
                        elif col == 'Type_local':
                            encoded_val = 0
                        elif col == 'Commune':
                            encoded_val = abs(hash(str(original_val))) % 10000
                        
                        input_encoded[col] = encoded_val
                        encoding_log.append(f"{col}: '{original_val}' -> {encoded_val} (d√©faut)")
        else:
            # Pas d'encodeurs - utiliser l'encodage par d√©faut
            for col in ['Nature_mutation', 'Type_local', 'Commune']:
                if col in input_encoded.columns:
                    original_val = input_encoded[col].iloc[0]
                    original_values[col] = original_val
                    
                    if col == 'Nature_mutation':
                        encoded_val = 0  # Vente = 0
                    elif col == 'Type_local':
                        encoded_val = 0  # Maison = 0
                    elif col == 'Commune':
                        encoded_val = abs(hash(str(original_val))) % 10000
                    
                    input_encoded[col] = encoded_val
                    encoding_log.append(f"{col}: '{original_val}' -> {encoded_val} (d√©faut)")
            
    except Exception as e:
        st.error(f"Erreur lors de l'encodage: {str(e)}")
        raise e
    
    return input_encoded, original_values, encoding_log

def prepare_input_data_exact(code_departement, code_postal, commune, surface_reelle_bati, 
                           nombre_pieces_principales, surface_terrain, moyenne_taux):
    ligne = pd.DataFrame([{
        "Nature_mutation": "Vente",
        "Code_postal": code_postal,
        "Commune": commune,
        "Code_departement": code_departement,
        "Type_local": "Maison",
        "Surface_reelle_bati": surface_reelle_bati,
        "Nombre_pieces_principales": nombre_pieces_principales,
        "Surface_terrain": surface_terrain,
        "Moyenne_Taux": moyenne_taux
    }])
    
    # M√äME conversion qu'app.py
    categorical_cols = ["Nature_mutation", "Commune", "Type_local"]
    for col in categorical_cols:
        ligne[col] = ligne[col].astype("category")
    
    return ligne

def validate_inputs(**kwargs):
    """Validate user inputs"""
    errors = []
    
    if kwargs['surface_reelle_bati'] <= 0:
        errors.append("La surface b√¢tie doit √™tre positive")
    
    if kwargs['nombre_pieces_principales'] <= 0:
        errors.append("Le nombre de pi√®ces doit √™tre positif")
    
    if kwargs['surface_terrain'] < 0:
        errors.append("La surface du terrain ne peut pas √™tre n√©gative")
    
    if kwargs['moyenne_taux'] < 0:
        errors.append("Le taux d'int√©r√™t ne peut pas √™tre n√©gatif")
    
    return errors

def make_prediction_exact(model, input_data, encoders=None):
    """Make prediction with EXACT Jupyter methodology"""
    try:
        # √âTAPE 1: Encodage exact
        input_encoded, original_values, encoding_log = encode_categorical_features(input_data, encoders)
        
        # √âTAPE 2: V√©rification de l'ordre des colonnes
        if hasattr(model, 'feature_names_in_'):
            expected_features = list(model.feature_names_in_)
            current_features = list(input_encoded.columns)
            
            # CRITIQUE: R√©organiser les colonnes dans l'ordre attendu
            if set(expected_features) == set(current_features):
                input_encoded = input_encoded[expected_features]
                column_order_msg = "‚úÖ Ordre des colonnes ajust√© selon le mod√®le"
            else:
                missing_features = set(expected_features) - set(current_features)
                extra_features = set(current_features) - set(expected_features)
                column_order_msg = f"‚ö†Ô∏è Diff√©rences features: manquantes={missing_features}, extra={extra_features}"
        else:
            column_order_msg = "‚ÑπÔ∏è Ordre des colonnes non v√©rifi√© (pas d'info mod√®le)"
        
        # √âTAPE 3: Pr√©diction
        prediction = model.predict(input_encoded)[0]
        
        return {
            'prediction': prediction,
            'method': "Pr√©diction avec encodage exact",
            'input_encoded': input_encoded,
            'original_values': original_values,
            'encoding_log': encoding_log,
            'column_order_msg': column_order_msg,
            'success': True
        }
    
    except Exception as e:
        return {
            'prediction': None,
            'method': f"Erreur: {str(e)}",
            'input_encoded': None,
            'original_values': {},
            'encoding_log': [],
            'column_order_msg': "",
            'success': False,
            'error': str(e)
        }

# Load geographical data
geo_df = load_geo_data()

# Add model selection in sidebar
st.sidebar.subheader("ü§ñ S√©lection du Mod√®le")
model_choice = st.sidebar.selectbox(
    "Choisissez le mod√®le de pr√©diction:",
    options=["lgb", "cb"],
    format_func=lambda x: f"Model {x.upper()}" + (" (LightGBM)" if x == "lgb" else " (CatBoost)"),
    help="S√©lectionnez le mod√®le √† utiliser pour la pr√©diction"
)

# Load model and encoders based on user choice
model, encoders, model_info = load_model_and_encoders(model_choice)

# NOUVEAU: Section de diagnostic du mod√®le
#if model is not None and model_info:
 #   with st.expander("üîç Diagnostic du Mod√®le (pour d√©bogage)"):
  #      if 'expected_features' in model_info:
   #         st.write("**Features attendues par le mod√®le:**")
    #        for i, feature in enumerate(model_info['expected_features']):
     #           st.write(f"{i+1}. {feature}")
      #  
  #      if 'n_features' in model_info:
   #         st.write(f"**Nombre de features:** {model_info['n_features']}")
    #    
     #   if encoders:
      #      st.write("**Encodeurs disponibles:**")
       #     for key, encoder in encoders.items():
        #        if hasattr(encoder, 'classes_'):
         #           st.write(f"- {key}: {len(encoder.classes_)} classes")
          #      else:
           #         st.write(f"- {key}: {type(encoder).__name__}")

# Main application logic
if not geo_df.empty and model is not None:
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("üîß Param√®tres de pr√©diction")
        
        # Fixed parameters
        with st.container():
            st.markdown("**Param√®tres fixes:**")
            col_fixed1, col_fixed2 = st.columns(2)
            with col_fixed1:
                st.text_input("Nature mutation", value="Vente", disabled=True)
            with col_fixed2:
                st.text_input("Type local", value="Maison", disabled=True)
        
        st.markdown("---")
        st.subheader("üìç Localisation")
        
        # Location selection with improved UX
        departements_disponibles = sorted(geo_df['Code_departement'].unique())
        code_departement = st.selectbox(
            "Num√©ro du D√©partement",
            options=departements_disponibles,
            help="S√©lectionnez le d√©partement"
        )
        
        if code_departement:
            codes_postaux_filtres = sorted(
                geo_df[geo_df['Code_departement'] == code_departement]['Code_postal'].unique()
            )
            code_postal = st.selectbox(
                "Code Postal",
                options=codes_postaux_filtres,
                help=f"{len(codes_postaux_filtres)} codes postaux disponibles"
            )
        else:
            code_postal = None
            st.selectbox("Code Postal", options=[], disabled=True, 
                        help="S√©lectionnez d'abord un d√©partement")
        
        if code_postal:
            communes_filtrees = sorted(
                geo_df[
                    (geo_df['Code_departement'] == code_departement) & 
                    (geo_df['Code_postal'] == code_postal)
                ]['Commune'].unique()
            )
            commune = st.selectbox(
                "Commune",
                options=communes_filtrees,
                help=f"{len(communes_filtrees)} commune(s) disponible(s)"
            )
        else:
            commune = None
            st.selectbox("Commune", options=[], disabled=True,
                        help="S√©lectionnez d'abord un code postal")
        
        st.markdown("---")
        st.subheader("üèòÔ∏è Caract√©ristiques du bien")
        
        # Property characteristics with better validation
        surface_reelle_bati = st.number_input(
            "Surface habitable (m¬≤)",
            min_value=40.0,
            max_value=2000.0,
            value=90.0,
            step=1.0,
            help="Surface habitable du logement"
        )
        
        nombre_pieces_principales = st.number_input(
            "Nombre de pi√®ces",
            min_value=1,
            max_value=20,
            value=4,
            step=1,
            help="Chambres, salon, salle √† manger..."
        )
        
        surface_terrain = st.number_input(
            "Surface total du terrain (m¬≤)",
            min_value=0.0,
            max_value=100000.0,
            value=200.0,
            step=10.0,
            help="Surface totale du terrain"
        )
        
        moyenne_taux = st.number_input(
            "Taux d'int√©r√™t moyen d'emprunt (%)",
            min_value=0.0,
            max_value=15.0,
            value=3.5,
            step=0.1,
            help="Taux d'int√©r√™t immobilier actuel"
        )
        

    
    with col2:
        st.subheader("üîÆ R√©sultat de la pr√©diction")
        
        # Show selected model
        st.info(f"ü§ñ Mod√®le s√©lectionn√©: **{model_choice.upper()}**")
        
        # Validation
        validation_errors = validate_inputs(
            surface_reelle_bati=surface_reelle_bati,
            nombre_pieces_principales=nombre_pieces_principales,
            surface_terrain=surface_terrain,
            moyenne_taux=moyenne_taux
        )
        
        tous_champs_remplis = all([
            code_departement, code_postal, commune, 
            len(validation_errors) == 0
        ])
        
        if validation_errors:
            for error in validation_errors:
                st.error(f"‚ùå {error}")
        
        if not tous_champs_remplis:
            st.info("üìù Veuillez remplir correctement tous les champs pour effectuer une pr√©diction.")
        
        if st.button("üöÄ Pr√©dire la valeur fonci√®re", 
                    type="primary", 
                    use_container_width=True,
                    disabled=not tous_champs_remplis):
            
            with st.spinner("Calcul de la pr√©diction en cours..."):
                try:
                    # =========== NOUVELLE LOGIQUE SIMPLIFI√âE ===========
                    # Utilisation de la m√©thode app.py qui fonctionne
                    
                    ligne = pd.DataFrame([{
                        "Nature_mutation": "Vente",
                        "Code_postal": int(code_postal),
                        "Commune": str(commune),
                        "Code_departement": int(code_departement),
                        "Type_local": "Maison",
                        "Surface_reelle_bati": float(surface_reelle_bati),
                        "Nombre_pieces_principales": int(nombre_pieces_principales),
                        "Surface_terrain": float(surface_terrain),
                        "Moyenne_Taux": float(moyenne_taux)
                    }])
                    
                    # Conversion cat√©gorielle comme app.py
                    categorical_cols = ["Nature_mutation", "Commune", "Type_local"]
                    for col in categorical_cols:
                        ligne[col] = ligne[col].astype("category")
                    
                    # Pr√©diction directe
                    prediction = model.predict(ligne)[0]
                    
                    # =========== AFFICHAGE DES R√âSULTATS ===========
                    
                    st.success(f"‚úÖ Pr√©diction r√©alis√©e avec succ√®s avec le mod√®le {model_choice.upper()}!")
                    st.info("M√©thode utilis√©e: Logique app.py int√©gr√©e")
                    
                    # Main metrics
                    st.markdown('<div class="prediction-result">', unsafe_allow_html=True)
                    col_result1, col_result2 = st.columns(2)
                    
                    with col_result1:
                        st.metric(
                            label="üí∞ Valeur Fonci√®re Estim√©e",
                            value=f"{prediction:,.0f} ‚Ç¨",
                            help=f"Estimation bas√©e sur le mod√®le {model_choice.upper()}"
                        )
                    
                    with col_result2:
                        prix_m2 = prediction / surface_reelle_bati
                        st.metric(
                            label="üìê Prix au m¬≤",
                            value=f"{prix_m2:,.0f} ‚Ç¨/m¬≤",
                            help="Prix par m√®tre carr√© habitable"
                        )
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Additional insights
                    st.markdown("---")
                    st.subheader("üìä Analyse d√©taill√©e")
                    
                    col_analysis1, col_analysis2 = st.columns(2)
                    
                    with col_analysis1:
                        st.markdown("**üè† Caract√©ristiques du bien:**")
                        st.write(f"‚Ä¢ Surface habitable: {surface_reelle_bati:,.0f} m¬≤")
                        st.write(f"‚Ä¢ Nombre de pi√®ces: {nombre_pieces_principales}")
                        st.write(f"‚Ä¢ Surface terrain: {surface_terrain:,.0f} m¬≤")
                        
                        # Price per room
                        prix_par_piece = prediction / nombre_pieces_principales
                        st.write(f"‚Ä¢ Prix par pi√®ce: {prix_par_piece:,.0f} ‚Ç¨")
                    
                    with col_analysis2:
                        st.markdown("**üìç Localisation:**")
                        st.write(f"‚Ä¢ D√©partement: {code_departement}")
                        st.write(f"‚Ä¢ Code postal: {code_postal}")
                        st.write(f"‚Ä¢ Commune: {commune}")
                        st.write(f"‚Ä¢ Taux d'int√©r√™t: {moyenne_taux}%")
                    
                    # Market context
                    st.markdown('<div class="info-box">', unsafe_allow_html=True)
                    st.markdown("**üí° Contexte de march√©:**")
                    
                    if prix_m2 > 5000:
                        st.write("üî• Zone √† prix √©lev√© - march√© premium")
                    elif prix_m2 > 3000:
                        st.write("üìà Zone √† prix mod√©r√©-√©lev√©")
                    elif prix_m2 > 2000:
                        st.write("üìä Zone √† prix mod√©r√©")
                    else:
                        st.write("üíö Zone √† prix accessible")
                    
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Data visualization simplifi√©
 #                   with st.expander("üîç Donn√©es utilis√©es pour la pr√©diction"):
  #                      st.subheader("DataFrame d'entr√©e")
  #                      st.dataframe(ligne, use_container_width=True)
  #                      
  #                      st.subheader("Types de donn√©es")
  #                      dtypes_info = pd.DataFrame({
  #                          'Colonne': ligne.columns,
  #                          'Type': [str(dtype) for dtype in ligne.dtypes],
   #                         'Valeur': [ligne[col].iloc[0] for col in ligne.columns]
  #                      })
  #                      st.dataframe(dtypes_info, use_container_width=True)
                        
   #                     st.success("‚úÖ Donn√©es trait√©es avec la m√©thode app.py")
                
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la pr√©diction: {str(e)}")
                    
                    with st.expander("üîß Informations de diagnostic"):
                        st.write("**Erreur:**", str(e))
                        st.write("**Type d'erreur:**", type(e).__name__)
                        
                        try:
                            import traceback
                            st.code(traceback.format_exc())
                        except:
                            pass


else:
    # Error states
    if geo_df.empty:
        st.error("‚ùå Donn√©es g√©ographiques non disponibles")
        st.info("V√©rifiez la pr√©sence du fichier 'Liste_Departement_Ville_ValeursFoncieres-all_fitre.csv'")
    
    if model is None:
        st.error(f"‚ùå Mod√®le {model_choice.upper()} non disponible")
        st.info(f"V√©rifiez la pr√©sence du fichier 'model_{model_choice}.pkl'")